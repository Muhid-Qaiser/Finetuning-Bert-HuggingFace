{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e21a58b26954db2acad88690c81638c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/6.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f7b9428fb84f06b5737dd450194a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/299M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f094e5a7d6b42afa3a660f16b9b644c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/23.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a10be4f357a542019d6593067d77dc42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/650000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0908a3bfef084652926a5ffe669b0019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'label': 0,\n",
       " 'text': 'My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\\\nThe cashier took my friends\\'s order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\\'s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\\\\"serving off their orders\\\\\" when they didn\\'t have their food. But neither cashier was anywhere near those controls, and the manager was the one serving food to customers and clearing the boards.\\\\nThe manager was rude when giving me my order. She didn\\'t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\\\nI\\'ve eaten at various McDonalds restaurants for over 30 years. I\\'ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "dataset[\"train\"][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b1e5e730184fd18e195cb59524a246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\D-Program Files\\Python\\Lib\\site-packages\\huggingface_hub\\file_download.py:159: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\pc\\.cache\\huggingface\\hub\\models--google-bert--bert-base-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10019821bea4a9daab72904e88deb09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "536cb690a50e4c4cbdabf0db45e61342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1402db923c434322a88aa76a54641196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2948abeb3f304ec6a33a60f83269524f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/650000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95789cf7543f4ee7b691120a7cc81514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\D-Program Files\\Python\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a16af0d1bc4ee0b2ab202bd31a857a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"google-bert/bert-base-cased\", num_labels=5, torch_dtype=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe6e87092654f489328e8eb9f698ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer_bert\", eval_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\D-Program Files\\Python\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [375/375 01:31, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.137819</td>\n",
       "      <td>0.496000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.045357</td>\n",
       "      <td>0.559000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.053725</td>\n",
       "      <td>0.587000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=375, training_loss=1.0365265299479167, metrics={'train_runtime': 92.6222, 'train_samples_per_second': 32.39, 'train_steps_per_second': 4.049, 'total_flos': 789354427392000.0, 'train_loss': 1.0365265299479167, 'epoch': 3.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.0537248849868774,\n",
       " 'eval_accuracy': 0.587,\n",
       " 'eval_runtime': 7.4994,\n",
       " 'eval_samples_per_second': 133.344,\n",
       " 'eval_steps_per_second': 16.668,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 2,\n",
       " 'text': \"Review for the Lounge/Club:\\\\nEvery time I go to Vegas this is always one of my stops- primarily because of the view. I started going years ago before it was super hyped up and packed almost all the time. I also remember the days when the Witch Doctors were twice the size they are now (and weaker than they used to be!). Voodoo hasn't changed much in the past 5 years except going cheap on the drinks and over packing the club with VIP sections that are unused (which is totally annoying if you're trying to see the view without a bunch of drunk asses running into you). \\\\n\\\\nThe DJs are consistently good and it has a very, very mixed crowd. However, I only keep coming back for the view- it doesn't compare to anything else. Ghost Bar has nothing on this place. \\\\n\\\\nAlso, over the years the award winning flair bartending has leveled off (I think I saw one bottle throw the whole time we were there) and it's not nearly the show it used to be which is really disappointing. If you ever have a chance to catch the episode of Three Sheets on Spike where Zane goes to Vegas- you'll see what I mean. The show was filmed several years ago and even there you can see the Witch Doctor and the flair are way better than they are now. \\\\n\\\\nFor newcomers I think this is a great place to at least see once just because the view is so amazing. However, for those who have been going back over and over again- it's turning into a huge disappointment. \\\\n\\\\nFor the Restaurant:\\\\n\\\\nI've dined here several times and price-wise it runs about the same as any other high end steak house you'd find on the strip. Mostly we ate here out of convenience since the selection at Rio isn't the greatest for food. The service has been reasonably decent and the food was good however, if dinner is going to cost around $100 a person I want to be wowed. The whole experience didn't seem like a 5 star dining like when we went to Strip House (wow! by the way). The servers were friendly but only slightly knowledgeable about the wine list and it seemed like there wasn't enough coverage for the tables which made dinner take forever. I don't really remember much more than that which is disappointing because I wish it were more memorable for the price paid. Been there, done that- won't be back to Voodoo Steak when there's so many better options for the same price.\",\n",
       " 'input_ids': [101,\n",
       "  4960,\n",
       "  1111,\n",
       "  1103,\n",
       "  26135,\n",
       "  120,\n",
       "  1998,\n",
       "  131,\n",
       "  165,\n",
       "  183,\n",
       "  2036,\n",
       "  4121,\n",
       "  1183,\n",
       "  1159,\n",
       "  146,\n",
       "  1301,\n",
       "  1106,\n",
       "  6554,\n",
       "  1142,\n",
       "  1110,\n",
       "  1579,\n",
       "  1141,\n",
       "  1104,\n",
       "  1139,\n",
       "  6260,\n",
       "  118,\n",
       "  3120,\n",
       "  1272,\n",
       "  1104,\n",
       "  1103,\n",
       "  2458,\n",
       "  119,\n",
       "  146,\n",
       "  1408,\n",
       "  1280,\n",
       "  1201,\n",
       "  2403,\n",
       "  1196,\n",
       "  1122,\n",
       "  1108,\n",
       "  7688,\n",
       "  177,\n",
       "  16726,\n",
       "  1181,\n",
       "  1146,\n",
       "  1105,\n",
       "  8733,\n",
       "  1593,\n",
       "  1155,\n",
       "  1103,\n",
       "  1159,\n",
       "  119,\n",
       "  146,\n",
       "  1145,\n",
       "  2676,\n",
       "  1103,\n",
       "  1552,\n",
       "  1165,\n",
       "  1103,\n",
       "  14057,\n",
       "  21232,\n",
       "  1127,\n",
       "  3059,\n",
       "  1103,\n",
       "  2060,\n",
       "  1152,\n",
       "  1132,\n",
       "  1208,\n",
       "  113,\n",
       "  1105,\n",
       "  16990,\n",
       "  1190,\n",
       "  1152,\n",
       "  1215,\n",
       "  1106,\n",
       "  1129,\n",
       "  106,\n",
       "  114,\n",
       "  119,\n",
       "  159,\n",
       "  25053,\n",
       "  8186,\n",
       "  112,\n",
       "  189,\n",
       "  2014,\n",
       "  1277,\n",
       "  1107,\n",
       "  1103,\n",
       "  1763,\n",
       "  126,\n",
       "  1201,\n",
       "  2589,\n",
       "  1280,\n",
       "  10928,\n",
       "  1113,\n",
       "  1103,\n",
       "  8898,\n",
       "  1105,\n",
       "  1166,\n",
       "  16360,\n",
       "  1103,\n",
       "  1526,\n",
       "  1114,\n",
       "  24425,\n",
       "  4886,\n",
       "  1115,\n",
       "  1132,\n",
       "  16217,\n",
       "  113,\n",
       "  1134,\n",
       "  1110,\n",
       "  5733,\n",
       "  17090,\n",
       "  1191,\n",
       "  1128,\n",
       "  112,\n",
       "  1231,\n",
       "  1774,\n",
       "  1106,\n",
       "  1267,\n",
       "  1103,\n",
       "  2458,\n",
       "  1443,\n",
       "  170,\n",
       "  9670,\n",
       "  1104,\n",
       "  6882,\n",
       "  3919,\n",
       "  1279,\n",
       "  1919,\n",
       "  1154,\n",
       "  1128,\n",
       "  114,\n",
       "  119,\n",
       "  165,\n",
       "  183,\n",
       "  165,\n",
       "  183,\n",
       "  1942,\n",
       "  4638,\n",
       "  27353,\n",
       "  1132,\n",
       "  10887,\n",
       "  1363,\n",
       "  1105,\n",
       "  1122,\n",
       "  1144,\n",
       "  170,\n",
       "  1304,\n",
       "  117,\n",
       "  1304,\n",
       "  3216,\n",
       "  3515,\n",
       "  119,\n",
       "  1438,\n",
       "  117,\n",
       "  146,\n",
       "  1178,\n",
       "  1712,\n",
       "  1909,\n",
       "  1171,\n",
       "  1111,\n",
       "  1103,\n",
       "  2458,\n",
       "  118,\n",
       "  1122,\n",
       "  2144,\n",
       "  112,\n",
       "  189,\n",
       "  14133,\n",
       "  1106,\n",
       "  1625,\n",
       "  1950,\n",
       "  119,\n",
       "  9040,\n",
       "  6523,\n",
       "  1144,\n",
       "  1720,\n",
       "  1113,\n",
       "  1142,\n",
       "  1282,\n",
       "  119,\n",
       "  165,\n",
       "  183,\n",
       "  165,\n",
       "  183,\n",
       "  1592,\n",
       "  3447,\n",
       "  1186,\n",
       "  117,\n",
       "  1166,\n",
       "  1103,\n",
       "  1201,\n",
       "  1103,\n",
       "  2574,\n",
       "  2183,\n",
       "  22593,\n",
       "  8341,\n",
       "  2927,\n",
       "  22835,\n",
       "  1144,\n",
       "  25569,\n",
       "  1228,\n",
       "  113,\n",
       "  146,\n",
       "  1341,\n",
       "  146,\n",
       "  1486,\n",
       "  1141,\n",
       "  5346,\n",
       "  4932,\n",
       "  1103,\n",
       "  2006,\n",
       "  1159,\n",
       "  1195,\n",
       "  1127,\n",
       "  1175,\n",
       "  114,\n",
       "  1105,\n",
       "  1122,\n",
       "  112,\n",
       "  188,\n",
       "  1136,\n",
       "  2212,\n",
       "  1103,\n",
       "  1437,\n",
       "  1122,\n",
       "  1215,\n",
       "  1106,\n",
       "  1129,\n",
       "  1134,\n",
       "  1110,\n",
       "  1541,\n",
       "  16703,\n",
       "  119,\n",
       "  1409,\n",
       "  1128,\n",
       "  1518,\n",
       "  1138,\n",
       "  170,\n",
       "  2640,\n",
       "  1106,\n",
       "  3963,\n",
       "  1103,\n",
       "  2004,\n",
       "  1104,\n",
       "  2677,\n",
       "  1153,\n",
       "  6248,\n",
       "  1113,\n",
       "  12901,\n",
       "  1187,\n",
       "  6359,\n",
       "  2947,\n",
       "  1106,\n",
       "  6554,\n",
       "  118,\n",
       "  1128,\n",
       "  112,\n",
       "  1325,\n",
       "  1267,\n",
       "  1184,\n",
       "  146,\n",
       "  1928,\n",
       "  119,\n",
       "  1109,\n",
       "  1437,\n",
       "  1108,\n",
       "  5819,\n",
       "  1317,\n",
       "  1201,\n",
       "  2403,\n",
       "  1105,\n",
       "  1256,\n",
       "  1175,\n",
       "  1128,\n",
       "  1169,\n",
       "  1267,\n",
       "  1103,\n",
       "  14057,\n",
       "  4157,\n",
       "  1105,\n",
       "  1103,\n",
       "  22593,\n",
       "  8341,\n",
       "  1132,\n",
       "  1236,\n",
       "  1618,\n",
       "  1190,\n",
       "  1152,\n",
       "  1132,\n",
       "  1208,\n",
       "  119,\n",
       "  165,\n",
       "  183,\n",
       "  165,\n",
       "  183,\n",
       "  2271,\n",
       "  1766,\n",
       "  25551,\n",
       "  1116,\n",
       "  146,\n",
       "  1341,\n",
       "  1142,\n",
       "  1110,\n",
       "  170,\n",
       "  1632,\n",
       "  1282,\n",
       "  1106,\n",
       "  1120,\n",
       "  1655,\n",
       "  1267,\n",
       "  1517,\n",
       "  1198,\n",
       "  1272,\n",
       "  1103,\n",
       "  2458,\n",
       "  1110,\n",
       "  1177,\n",
       "  6929,\n",
       "  119,\n",
       "  1438,\n",
       "  117,\n",
       "  1111,\n",
       "  1343,\n",
       "  1150,\n",
       "  1138,\n",
       "  1151,\n",
       "  1280,\n",
       "  1171,\n",
       "  1166,\n",
       "  1105,\n",
       "  1166,\n",
       "  1254,\n",
       "  118,\n",
       "  1122,\n",
       "  112,\n",
       "  188,\n",
       "  3219,\n",
       "  1154,\n",
       "  170,\n",
       "  3321,\n",
       "  10866,\n",
       "  119,\n",
       "  165,\n",
       "  183,\n",
       "  165,\n",
       "  183,\n",
       "  2271,\n",
       "  1766,\n",
       "  1103,\n",
       "  17925,\n",
       "  131,\n",
       "  165,\n",
       "  183,\n",
       "  165,\n",
       "  183,\n",
       "  2240,\n",
       "  112,\n",
       "  1396,\n",
       "  28028,\n",
       "  1174,\n",
       "  1303,\n",
       "  1317,\n",
       "  1551,\n",
       "  1105,\n",
       "  3945,\n",
       "  118,\n",
       "  10228,\n",
       "  1122,\n",
       "  2326,\n",
       "  1164,\n",
       "  1103,\n",
       "  1269,\n",
       "  1112,\n",
       "  1251,\n",
       "  1168,\n",
       "  1344,\n",
       "  1322,\n",
       "  26704,\n",
       "  1402,\n",
       "  1128,\n",
       "  112,\n",
       "  173,\n",
       "  1525,\n",
       "  1113,\n",
       "  1103,\n",
       "  6322,\n",
       "  119,\n",
       "  21981,\n",
       "  1195,\n",
       "  8756,\n",
       "  1303,\n",
       "  1149,\n",
       "  1104,\n",
       "  16670,\n",
       "  1290,\n",
       "  1103,\n",
       "  4557,\n",
       "  1120,\n",
       "  5470,\n",
       "  2762,\n",
       "  112,\n",
       "  189,\n",
       "  1103,\n",
       "  4459,\n",
       "  1111,\n",
       "  2094,\n",
       "  119,\n",
       "  1109,\n",
       "  1555,\n",
       "  1144,\n",
       "  1151,\n",
       "  17517,\n",
       "  11858,\n",
       "  1105,\n",
       "  1103,\n",
       "  2094,\n",
       "  1108,\n",
       "  1363,\n",
       "  1649,\n",
       "  117,\n",
       "  1191,\n",
       "  4014,\n",
       "  1110,\n",
       "  1280,\n",
       "  1106,\n",
       "  2616,\n",
       "  1213,\n",
       "  109,\n",
       "  1620,\n",
       "  170,\n",
       "  1825,\n",
       "  146,\n",
       "  1328,\n",
       "  1106,\n",
       "  1129,\n",
       "  192,\n",
       "  12595,\n",
       "  119,\n",
       "  1109,\n",
       "  2006,\n",
       "  2541,\n",
       "  1238,\n",
       "  112,\n",
       "  189,\n",
       "  3166,\n",
       "  1176,\n",
       "  170,\n",
       "  126,\n",
       "  2851,\n",
       "  7659,\n",
       "  1176,\n",
       "  1165,\n",
       "  1195,\n",
       "  1355,\n",
       "  1106,\n",
       "  18534,\n",
       "  1585,\n",
       "  113,\n",
       "  192,\n",
       "  4064,\n",
       "  106,\n",
       "  1118,\n",
       "  1103,\n",
       "  1236,\n",
       "  114,\n",
       "  119,\n",
       "  1109,\n",
       "  16096,\n",
       "  1127,\n",
       "  4931,\n",
       "  1133,\n",
       "  1178,\n",
       "  2776,\n",
       "  3044,\n",
       "  1895,\n",
       "  1164,\n",
       "  1103,\n",
       "  4077,\n",
       "  2190,\n",
       "  1105,\n",
       "  1122,\n",
       "  1882,\n",
       "  1176,\n",
       "  1175,\n",
       "  1445,\n",
       "  112,\n",
       "  189,\n",
       "  1536,\n",
       "  5811,\n",
       "  1111,\n",
       "  1103,\n",
       "  7072,\n",
       "  1134,\n",
       "  1189,\n",
       "  4014,\n",
       "  1321,\n",
       "  5221,\n",
       "  119,\n",
       "  146,\n",
       "  1274,\n",
       "  112,\n",
       "  189,\n",
       "  1541,\n",
       "  2676,\n",
       "  1277,\n",
       "  1167,\n",
       "  1190,\n",
       "  1115,\n",
       "  1134,\n",
       "  102],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print( small_train_dataset[1]['text'] )\n",
    "small_train_dataset[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\c'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\c'\n",
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_296\\36330538.py:5: SyntaxWarning: invalid escape sequence '\\c'\n",
      "  model_name = 'test_trainer\\checkpoint-375'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 1\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load the fine-tuned model and tokenizer\n",
    "model_name = 'test_trainer\\checkpoint-375'\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# Function to generate answers\n",
    "def generate_answer(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predicted_class_id = torch.argmax(logits, dim=-1).item()\n",
    "    return predicted_class_id\n",
    "\n",
    "# Example usage\n",
    "text = \"Review for the Lounge/Club:\\\\nEvery time I go to Vegas this is always one of my stops- primarily because of the view. I started going years ago before it was super hyped up and packed almost all the time. I also remember the days when the Witch Doctors were twice the size they are now (and weaker than they used to be!). Voodoo hasn't changed much in the past 5 years except going cheap on the drinks and over packing the club with VIP sections that are unused (which is totally annoying if you're trying to see the view without a bunch of drunk asses running into you). \\\\n\\\\nThe DJs are consistently good and it has a very, very mixed crowd. However, I only keep coming back for the view- it doesn't compare to anything else. Ghost Bar has nothing on this place. \\\\n\\\\nAlso, over the years the award winning flair bartending has leveled off (I think I saw one bottle throw the whole time we were there) and it's not nearly the show it used to be which is really disappointing. If you ever have a chance to catch the episode of Three Sheets on Spike where Zane goes to Vegas- you'll see what I mean. The show was filmed several years ago and even there you can see the Witch Doctor and the flair are way better than they are now. \\\\n\\\\nFor newcomers I think this is a great place to at least see once just because the view is so amazing. However, for those who have been going back over and over again- it's turning into a huge disappointment. \\\\n\\\\nFor the Restaurant:\\\\n\\\\nI've dined here several times and price-wise it runs about the same as any other high end steak house you'd find on the strip. Mostly we ate here out of convenience since the selection at Rio isn't the greatest for food. The service has been reasonably decent and the food was good however, if dinner is going to cost around $100 a person I want to be wowed. The whole experience didn't seem like a 5 star dining like when we went to Strip House (wow! by the way). The servers were friendly but only slightly knowledgeable about the wine list and it seemed like there wasn't enough coverage for the tables which made dinner take forever. I don't really remember much more than that which is disappointing because I wish it were more memorable for the price paid. Been there, done that- won't be back to Voodoo Steak when there's so many better options for the same price.\"\n",
    "answer = generate_answer(text)\n",
    "print(f\"Predicted class: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['label', 'text', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 1000\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
